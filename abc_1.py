# -*- coding: utf-8 -*-
"""ABC_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12or29e-Ek5R8yaI0fsovjZ-Vm-1zUFOW

**Sentence and word tokenizer**
"""

import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize, word_tokenize
text="In various contexts, the term 'world'takes a more restricted meaning associated, for example, with the Earth and all life on it, with humanity"
print(text)

print(sent_tokenize(text))
print(word_tokenize(text))

"""**Tab Tokenizer**"""

from nltk.tokenize import TabTokenizer
tk=TabTokenizer()
text="Live for\t doing good deeds..\t.$$&* \n not \t for doing sins"
tab=tk.tokenize(text)
print(tab)

"""**Space Tokenizer**"""

from nltk.tokenize import SpaceTokenizer
tk=SpaceTokenizer()
text="The subject contents related to NLP"
space=tk.tokenize(text)
print(space)

"""**Line Tokenizer**"""

from nltk.tokenize import LineTokenizer
tk=LineTokenizer(blanklines ='keep')
text="The price\n\n of burger \nin Burger King is Rs.36.\n"
line=tk.tokenize(text)
print(text)
print(line)

"""**Punctuation Tokenizer**"""

from nltk.tokenize import WordPunctTokenizer
tk=WordPunctTokenizer()
text="World Chocolate Day, Celebrated for the first time in 2009, commemorates the rich history of chocalte dating back to the Aztec period around '1400'BC. During"
punc=tk.tokenize(text)
print(punc)

"""**Word Frequency Count**"""

from nltk.probability import ConditionalFreqDist
from nltk.tokenize import word_tokenize
tk= ConditionalFreqDist()
text="This world is very very very beautiful; because the people of this world are beautiful."
for word in word_tokenize(text):
  condition = len(word)
  tk[condition][word] += 1
tk[2]